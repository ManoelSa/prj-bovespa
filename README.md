# Projeto de Coleta e Refinamento de Dados Bovespa

Um pipeline ETL completo para coletar, refinar e disponibilizar dados di√°rios da B3 (Bovespa) em um Data Lakehouse na AWS.

## üéØ Objetivo

O principal objetivo deste projeto √© automatizar a coleta di√°ria dos dados do √≠ndice IBOV (Bovespa) da B3, persistir essas informa√ß√µes de forma estruturada e refinada em um Data Lakehouse na AWS, e disponibiliz√°-las para consumo anal√≠tico atrav√©s do Amazon Athena. O pipeline segue uma arquitetura robusta para garantir a qualidade, rastreabilidade e acessibilidade dos dados.

## üåü Vis√£o Geral

Este projeto √© um pipeline ETL (Extract, Transform, Load) que abrange desde a extra√ß√£o dos dados brutos do site da B3 at√© a disponibiliza√ß√£o dos dados refinados para consultas. Ele se baseia em servi√ßos da AWS para garantir escalabilidade, resili√™ncia e automa√ß√£o.

O fluxo principal √© dividido em etapas, come√ßando com a coleta de dados ate a disponibiliza√ß√£o para an√°lise.

## ‚ú® Principais Funcionalidades

* **Extra√ß√£o Di√°ria:** Coleta autom√°tica dos dados dos componentes do √≠ndice Bovespa (IBOV) da B3.
* **Ingest√£o de Dados Brutos:** Armazenamento dos dados brutos no S3 em formato Parquet com particionamento di√°rio, seguindo o padr√£o de uma camada `raw` do Data Lake.
* **Processamento ETL Gerenciado:** Utiliza√ß√£o do AWS Glue para transformar e refinar os dados, seguindo um fluxo visual de desenvolvimento.
* **Armazenamento de Dados Refinados:** Persist√™ncia dos dados transformados em uma camada `refined` do Data Lake, tamb√©m em formato Parquet e com particionamento inteligente por data e a√ß√£o.
* **Cat√°logo de Dados Autom√°tico:** Integra√ß√£o com o AWS Glue Data Catalog para metadados e cria√ß√£o autom√°tica de tabelas.
* **Disponibilidade para An√°lise:** Dados prontos para serem consultados e analisados via Amazon Athena.

## üèõÔ∏è Arquitetura e Fluxo do ETL

O pipeline ETL completo segue uma arquitetura serverless e gerenciada pela AWS, dividida nas seguintes etapas, cumprindo os requisitos do projeto:

1.  **Extra√ß√£o e Ingest√£o da Camada Raw (Lambda com Imagem de Cont√™iner no ECR) - Requisito 1 & 2:**
    * O script Python respons√°vel pelo **scraping dos dados do site da B3** e pela ingest√£o dos dados brutos no S3 √© empacotado em uma **imagem Docker**.
    * Esta imagem Docker √© publicada no **Amazon Elastic Container Registry (ECR)**.
    * Uma **fun√ß√£o AWS Lambda** √© configurada para usar esta imagem de cont√™iner. Esta Lambda executa o script, que coleta os dados do preg√£o di√°rio do IBOV e os converte para o formato **Parquet**.
    * Os dados s√£o ent√£o **ingeridos no S3** em um bucket dedicado √† camada `raw` (`bck-bovespa`), com uma estrutura de **particionamento di√°rio** (`raw/dataproc=YYYYMMDD/`).
    

2.  **Orquestra√ß√£o do ETL (Lambda e Glue) - Requisito 3 & 4:**
    * O upload do arquivo Parquet para o bucket `raw` no S3 **aciona um evento S3**.
    * Este evento **invoca uma segunda fun√ß√£o AWS Lambda** (constru√≠da em python, focada apenas em iniciar o job).
    * Esta segunda fun√ß√£o Lambda, por sua vez, **chama um job de ETL no AWS Glue**.

3.  **Transforma√ß√£o e Refinamento (AWS Glue) - Requisito 5 & 6:**
    * O **Job Glue** √© o cora√ß√£o da transforma√ß√£o dos dados. Ele √© **desenvolvido no modo visual** (AWS Glue Studio) para facilitar a constru√ß√£o do pipeline de processamento.
    * O job l√™ os dados da camada `raw` no S3.
    * Realiza as transforma√ß√µes e valida√ß√µes necess√°rias nos dados do preg√£o.
    * Os **dados refinados s√£o salvos em formato Parquet** em uma pasta na camada `refined` do S3, **particionados por data** (`dt_ref=YYYY-MM-DD/`) **e pelo c√≥digo da a√ß√£o do preg√£o** (ex: `codigo=ABEV3/`).
    

4.  **Cat√°logo de Dados (AWS Glue Data Catalog) - Requisito 7:**
    * Ao final da execu√ß√£o, o Job Glue **automaticamente cataloga os dados refinados no Glue Catalog**.
    * Ele **cria uma tabela no banco de dados `default`** (ou outro especificado) do Glue Catalog, inferindo o esquema dos dados Parquet.

5.  **Disponibilidade para An√°lise (Amazon Athena) - Requisito 8:**
    * Com a tabela catalogada no Glue Data Catalog, os **dados refinados tornam-se imediatamente dispon√≠veis e leg√≠veis para consultas SQL atrav√©s do Amazon Athena**. Isso permite que analistas de dados e ferramentas de BI acessem os dados de forma f√°cil e perform√°tica.
    

Este pipeline garante que os dados da B3 sejam processados de forma eficiente, governada e prontos para consumo.

## üõ†Ô∏è Detalhes de Implementa√ß√£o

### Tecnologias Utilizadas

* **Python:** Linguagem de programa√ß√£o principal.
* **`requests`:** Para fazer requisi√ß√µes HTTP √† API da B3.
* **`pandas`:** Para manipula√ß√£o e tratamento de dados em DataFrame.
* **`pyarrow`:** Para convers√£o de DataFrame para o formato Parquet.
* **`boto3`:** SDK da AWS para interagir com servi√ßos como o S3.
* **AWS S3:** Servi√ßo de armazenamento de objetos para o Data Lake.
* **AWS Lambda:** Servi√ßo de computa√ß√£o serverless, utilizado para a fun√ß√£o de scraping/ingest√£o (baseada em imagem de cont√™iner) e para a orquestra√ß√£o do Glue Job.
* **AWS ECR (Elastic Container Registry):** Reposit√≥rio para armazenar a imagem Docker do scraper.
* **AWS Glue:** Servi√ßo ETL serverless para transforma√ß√£o e cataloga√ß√£o de dados.
* **Amazon Athena:** Servi√ßo de consulta interativa para dados no S3.
* **Event notifications:** Para acionamento dos processos ap√≥s arquivo pousado no S3 na camada raw.
* **AWS EventBridge:** Para agendamento da execu√ß√£o di√°ria do cont√™iner do scraper.

### Representa√ß√£o do Fluxo

```text
[Agendador Di√°rio: EventBridge]
        |
        | (Invoca) 
        v
[Lambda (Scraping B3 + Ingest√£o Raw no S3)]
        |
        | (extracao_bovespa_docker)
        v
[S3 - Camada Raw (Dados Brutos Parquet)]
        |
        | (Dispara Evento)
        v
[Lambda (Orquestrador Glue Job)]
        |
        | (start_job_glue)
        v
[AWS Glue Job (Refinamento ETL)]
        |
        | (etl_bovespa)
        v
[S3 - Camada Refined (Dados Refinados Parquet)]
        |
        | (Cat√°logo Autom√°tico)
        v
[AWS Glue Data Catalog]
        | 
        | (catalog)
        v
[Amazon Athena (Consulta Anal√≠tica)]
```